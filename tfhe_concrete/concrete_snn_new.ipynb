{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/local/ASURITE/nnjungle/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torchsummary import summary\n",
    "\n",
    "from concrete import fhe\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparams\n",
    "no_epochs = 2\n",
    "batch_size = 32\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform the dataset into tensors normalized range [-1, 1]\n",
    "transform = transforms.Compose(\n",
    "            [transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5),(0.5))     \n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data sets downloading and reading\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', \n",
    "                                        train=True,\n",
    "                                        download=True,\n",
    "                                        transform=transform\n",
    "                                        )\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='data',\n",
    "                                        train=False,\n",
    "                                        download=True,\n",
    "                                        transform=transform\n",
    "                                        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uint8\n",
      "(100, 1, 28, 28)\n",
      "Shape of x_train from MNIST: (100, 1, 28, 28)\n",
      "Shape of x_test from MNIST: (100, 1, 28, 28)\n",
      "Shape of y_train from MNIST: (100,)\n",
      "Shape of y_test from MNIST: (100,)\n"
     ]
    }
   ],
   "source": [
    "# Extract features (images) and labels from MNIST dataset\n",
    "mnist_features = train_dataset.data.numpy().reshape(-1, 28, 28)\n",
    "mnist_labels = train_dataset.targets.numpy()\n",
    "\n",
    "# Reshape and expand dimensions to match the structure of load_digits dataset\n",
    "x_train_mnist = np.expand_dims(mnist_features, 1)\n",
    "\n",
    "# Split the MNIST data into train and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x_train_mnist, mnist_labels,  train_size=100, test_size=100, shuffle=True, random_state=42\n",
    ")\n",
    "\n",
    "#x_train = x_train.astype('float64')\n",
    "print(x_train.dtype)\n",
    "print(x_train.shape)\n",
    "\n",
    "#print(x_train)\n",
    "# plt.imshow(x_train[0,0], cmap='grey')\n",
    "# plt.show()\n",
    "# Verify the shapes\n",
    "print(\"Shape of x_train from MNIST:\", x_train.shape)\n",
    "print(\"Shape of x_test from MNIST:\", x_test.shape)\n",
    "print(\"Shape of y_train from MNIST:\", y_train.shape)\n",
    "print(\"Shape of y_test from MNIST:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "configuration = fhe.Configuration(\n",
    "    comparison_strategy_preference=fhe.ComparisonStrategy.ONE_TLU_PROMOTED,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the lookup table to used for the spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# array_table = np.zeros(1000)\n",
    "# array_table[:500] = 1\n",
    "lookup_table = (0,) * 500 + (1,) * 500\n",
    "\n",
    "# lookup_table = [array_table]\n",
    "# print(lookup_table)\n",
    "\n",
    "table = fhe.LookupTable(lookup_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 3, 3)\n"
     ]
    }
   ],
   "source": [
    "# weight = np.array([[2, 1], [3, 2]]).reshape(1, 1, 2, 2)\n",
    "# selected_weights = np.array(x_train[0, 0, :, :]).reshape(1, 1, 28, 28)\n",
    "weight = np.random.randint(0, 4, size=(1, 1, 3, 3))\n",
    "print(weight.shape)\n",
    "fhe_spikes_array = np.empty(shape=(1, 1, 1, 24), dtype=object)\n",
    "# print(weight)\n",
    "\n",
    "@fhe.compiler({\"x\": \"encrypted\"})\n",
    "def network_function(x):\n",
    "    print(\"we dey here\")\n",
    "    x = fhe.conv(x, weight, strides=(1, 1))\n",
    "    print(\"first conv done\")\n",
    "    x = fhe.conv(x, weight, strides=(1, 1))\n",
    "    print(\"second conv done\")\n",
    "    # x = fhe.maxpool(x, kernel_shape=(2, 2), strides=(2, 2), dilations=(1, 1))\n",
    "    print(\"maxpool done\")\n",
    "    x = pbs_function(x)\n",
    "    print(\"pbs_func done\")\n",
    "    # conv2 = fhe.conv(conv1, selected_weights)\n",
    "    # print(pool1)\n",
    "    net_result = x\n",
    "    return net_result\n",
    "\n",
    "def pbs_function(xpbs):\n",
    "    print(\"in the pbs\")\n",
    "    # spiking_array = table[xpbs[0,0,0,1]]\n",
    "    print(xpbs[0])\n",
    "    # return spiking_array\n",
    "    # spiking_array = fhe.array(xpbs)\n",
    "    for i, x_pbs_row in enumerate(xpbs):\n",
    "        for j, pbs_row in enumerate(x_pbs_row):\n",
    "            for k, row in enumerate(pbs_row):\n",
    "                for l, cell in enumerate(row):\n",
    "                    xpbs[i, j, k, l] = table[cell]\n",
    "                    print(f'array[{i,j,k,l}]')\n",
    "                    # return fhe_spikes_array\n",
    "    return xpbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 28, 28)\n",
      "we dey here\n",
      "first conv done\n",
      "second conv done\n",
      "maxpool done\n",
      "in the pbs\n",
      "Tracer<output=EncryptedTensor<uint2, shape=(1, 24, 24)>>\n",
      "pbs_func done\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "x_train = np.array(x_train[0, 0, :, :]).reshape(1, 1, 28, 28)\n",
    "print(x_train.shape)\n",
    "\n",
    "inputset = [np.random.randint(0, 4, size=(1, 1, 28, 28)) for _ in range(10)]\n",
    "# print(inputset)\n",
    "circuit = network_function.compile(inputset)\n",
    "start = time.time()\n",
    "enc_sampe = circuit.encrypt(x_train)\n",
    "enc_result = circuit.run(enc_sampe)\n",
    "dec_result = circuit.decrypt(enc_result)\n",
    "print(dec_result.shape)\n",
    "print(dec_result)\n",
    "end = time.time()\n",
    "\n",
    "print(f'total time {end - start:.2f}s')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
