{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as functional\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torchsummary import summary\n",
    "\n",
    "from norse.torch.functional.lif import LIFParameters\n",
    "import norse.torch as snn\n",
    "\n",
    "from concrete import fhe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparams\n",
    "no_epochs = 2\n",
    "batch_size = 32\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform the dataset into tensors normalized range [-1, 1]\n",
    "transform = transforms.Compose(\n",
    "            [transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5),(0.5))     \n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data sets downloading and reading\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', \n",
    "                                        train=True,\n",
    "                                        download=True,\n",
    "                                        transform=transform\n",
    "                                        )\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='data',\n",
    "                                        train=False,\n",
    "                                        download=True,\n",
    "                                        transform=transform\n",
    "                                        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Dataloaders - used to load data into application for use\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=True\n",
    "                            )\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset,\n",
    "                                    batch_size=batch_size,\n",
    "                                    shuffle=False\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 26, 26]             320\n",
      "            Conv2d-2           [-1, 64, 24, 24]          18,496\n",
      "            Conv2d-3             [-1, 64, 8, 8]          36,928\n",
      "            Linear-4                   [-1, 64]         262,208\n",
      "            Linear-5                   [-1, 10]             650\n",
      "================================================================\n",
      "Total params: 318,602\n",
      "Trainable params: 318,602\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.48\n",
      "Params size (MB): 1.22\n",
      "Estimated Total Size (MB): 1.70\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "class ConvolutionalNeuralNet(nn.Module):\n",
    "    def __init__(self, \n",
    "                 num_classes: int = 10, \n",
    "                 method: str = \"super\", \n",
    "                 dtype: torch.dtype = torch.float,\n",
    "                 dt: float = 0.001):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n",
    "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, stride=3)\n",
    "        self.fc1 = nn.Linear(64 * 8 * 8, 64)\n",
    "        self.fc2 = nn.Linear(64, num_classes)\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "        x= self.conv1(x)\n",
    "        x = self.integrate_fire(x)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv3(x)\n",
    "        x = torch.relu(x)\n",
    "        x = x.flatten(1)\n",
    "        x = torch.relu(x)\n",
    "        x = self.fc1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "    def integrate_fire(x):\n",
    "        print(\"fire\")\n",
    "        return x\n",
    "    \n",
    "summary(ConvolutionalNeuralNet(10), (1,28,28), device='cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = ConvolutionalNeuralNet(10).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2/2 [01:06<00:00, 33.17s/it]\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "def train_one_epoch(net, optimizer, train_loader):\n",
    "    # Cross Entropy loss for classification when not using a softmax layer in the network\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "\n",
    "    net.train()\n",
    "    avg_loss = 0\n",
    "    for data, target in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = net(data)\n",
    "        loss_net = loss(output, target.long())\n",
    "        loss_net.backward()\n",
    "        optimizer.step()\n",
    "        avg_loss += loss_net.item()\n",
    "\n",
    "    return avg_loss / len(train_loader)\n",
    "\n",
    "# Create the tiny CNN with 10 output classes\n",
    "N_EPOCHS = no_epochs\n",
    "\n",
    "# Train the network with Adam, output the test set accuracy every epoch\n",
    "losses_bits = []\n",
    "optimizer = torch.optim.Adam(net.parameters())\n",
    "for _ in tqdm(range(N_EPOCHS), desc=\"Training\"):\n",
    "    losses_bits.append(train_one_epoch(net, optimizer, train_loader))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 98.73%\n"
     ]
    }
   ],
   "source": [
    "def test_torch(net, test_loader):\n",
    "    \"\"\"Test the network: measure accuracy on the test set.\"\"\"\n",
    "\n",
    "    # Freeze normalization layers\n",
    "    net.eval()\n",
    "\n",
    "    # Determine the total number of samples in the dataset\n",
    "    total_samples = len(test_loader.dataset)\n",
    "\n",
    "    all_y_pred = np.zeros((total_samples,), dtype=np.int64)\n",
    "    all_targets = np.zeros((total_samples,), dtype=np.int64)\n",
    "\n",
    "    # Iterate over the batches\n",
    "    idx = 0\n",
    "    for data, target in test_loader:\n",
    "        # Accumulate the ground truth labels\n",
    "        endidx = idx + target.shape[0]\n",
    "        all_targets[idx:endidx] = target.numpy()\n",
    "\n",
    "        # Run forward and get the predicted class id\n",
    "        output = net(data).argmax(1).detach().numpy()\n",
    "        all_y_pred[idx:endidx] = output\n",
    "\n",
    "        idx = endidx\n",
    "\n",
    "    # Print out the accuracy as a percentage\n",
    "    n_correct = np.sum(all_targets == all_y_pred)\n",
    "    accuracy = n_correct / total_samples * 100\n",
    "    print(f\"Test accuracy: {accuracy:.2f}%\")\n",
    "    \n",
    "\n",
    "# Call the test function\n",
    "test_torch(net, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
